<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>LLM Evaluation - Entrenar - Training &amp; Optimization Library</title>


        <!-- Custom HTML head -->

        <meta name="description" content="A comprehensive guide to building neural network training systems with autograd, optimizers, LoRA/QLoRA, and quantization using EXTREME TDD methodology">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "rust";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Entrenar - Training &amp; Optimization Library</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/paiml/entrenar" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/paiml/entrenar/edit/main/book/src/mlops/llm-evaluation.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="llm-evaluation"><a class="header" href="#llm-evaluation">LLM Evaluation</a></h1>
<p>Evaluate LLM outputs for relevance, coherence, groundedness, and harmfulness.</p>
<h2 id="toyota-principle-genchi-genbutsu"><a class="header" href="#toyota-principle-genchi-genbutsu">Toyota Principle: Genchi Genbutsu</a></h2>
<p>"Go and see" - directly observe model outputs to understand quality. Systematic evaluation enables data-driven improvement.</p>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::monitor::llm::{InMemoryLLMEvaluator, LLMEvaluator, EvalResult};

let mut evaluator = InMemoryLLMEvaluator::new();

// Evaluate a response
let result = evaluator.evaluate_response(
    "run-123",
    "What is machine learning?",           // prompt
    "Machine learning is a subset of AI...", // response
    Some("ML is artificial intelligence..."), // ground truth (optional)
)?;

println!("Relevance: {:.2}", result.relevance);
println!("Coherence: {:.2}", result.coherence);
println!("Groundedness: {:.2}", result.groundedness);
println!("Harmfulness: {:.2}", result.harmfulness);
<span class="boring">}</span></code></pre></pre>
<h2 id="evaluation-metrics"><a class="header" href="#evaluation-metrics">Evaluation Metrics</a></h2>
<h3 id="relevance-00---10"><a class="header" href="#relevance-00---10">Relevance (0.0 - 1.0)</a></h3>
<p>Measures how well the response addresses the prompt:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// High relevance: response directly answers the question
// Low relevance: response is off-topic or tangential

// Computed by word overlap between prompt and response
let relevance = result.relevance;
<span class="boring">}</span></code></pre></pre>
<h3 id="coherence-00---10"><a class="header" href="#coherence-00---10">Coherence (0.0 - 1.0)</a></h3>
<p>Measures logical flow and readability:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// High coherence: well-structured, logical flow
// Low coherence: disjointed, contradictory

// Computed by sentence structure analysis
let coherence = result.coherence;
<span class="boring">}</span></code></pre></pre>
<h3 id="groundedness-00---10"><a class="header" href="#groundedness-00---10">Groundedness (0.0 - 1.0)</a></h3>
<p>Measures faithfulness to source material:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// High groundedness: claims supported by context
// Low groundedness: hallucinated or unsupported claims

// Requires ground truth for comparison
let groundedness = result.groundedness;
<span class="boring">}</span></code></pre></pre>
<h3 id="harmfulness-00---10"><a class="header" href="#harmfulness-00---10">Harmfulness (0.0 - 1.0)</a></h3>
<p>Measures presence of harmful content:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Low harmfulness: safe, appropriate content
// High harmfulness: toxic, dangerous, or inappropriate

// Keyword-based detection
let harmfulness = result.harmfulness;
<span class="boring">}</span></code></pre></pre>
<h2 id="prompt-tracking"><a class="header" href="#prompt-tracking">Prompt Tracking</a></h2>
<p>Track prompt versions for A/B testing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::monitor::llm::{PromptVersion, PromptId};

let prompt = PromptVersion {
    id: PromptId::new("prompt-v1"),
    template: "Answer the following question: {question}".to_string(),
    version: 1,
    metadata: Some(serde_json::json!({
        "author": "alice",
        "description": "Basic QA prompt"
    })),
};

evaluator.track_prompt("run-123", &amp;prompt)?;

// List prompts for a run
let prompts = evaluator.get_prompts("run-123")?;
<span class="boring">}</span></code></pre></pre>
<h2 id="batch-evaluation"><a class="header" href="#batch-evaluation">Batch Evaluation</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let responses = vec![
    ("What is AI?", "AI is...", Some("Artificial intelligence...")),
    ("Explain ML", "ML uses...", Some("Machine learning...")),
    ("Define DL", "DL is...", Some("Deep learning...")),
];

let mut total_relevance = 0.0;

for (prompt, response, ground_truth) in responses {
    let result = evaluator.evaluate_response(
        "run-123",
        prompt,
        response,
        ground_truth,
    )?;

    total_relevance += result.relevance;
}

let avg_relevance = total_relevance / responses.len() as f64;
println!("Average relevance: {:.2}", avg_relevance);
<span class="boring">}</span></code></pre></pre>
<h2 id="llm-metrics-logging"><a class="header" href="#llm-metrics-logging">LLM Metrics Logging</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::monitor::llm::LLMMetrics;

let metrics = LLMMetrics {
    prompt_tokens: 50,
    completion_tokens: 150,
    total_tokens: 200,
    latency_ms: 500,
    model: "gpt-4".to_string(),
    temperature: Some(0.7),
    top_p: Some(0.9),
};

evaluator.log_llm_call("run-123", metrics)?;

// Retrieve metrics
let all_metrics = evaluator.get_metrics("run-123")?;
for m in all_metrics {
    println!("Tokens: {}, Latency: {}ms", m.total_tokens, m.latency_ms);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="aggregate-metrics"><a class="header" href="#aggregate-metrics">Aggregate Metrics</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::monitor::llm::AggregateMetrics;

let aggregate = evaluator.aggregate_metrics("run-123")?;

println!("Total calls: {}", aggregate.total_calls);
println!("Total tokens: {}", aggregate.total_tokens);
println!("Avg latency: {:.0}ms", aggregate.avg_latency_ms);
println!("Avg relevance: {:.2}", aggregate.avg_relevance);
println!("Avg coherence: {:.2}", aggregate.avg_coherence);
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-with-training"><a class="header" href="#integration-with-training">Integration with Training</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::train::callback::LLMEvalCallback;

let callback = LLMEvalCallback::new()
    .with_eval_samples(100)
    .with_ground_truth_path("data/test.jsonl");

trainer.add_callback(callback);

// Evaluation runs automatically at end of each epoch
trainer.fit(&amp;model, &amp;dataset)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="cargo-run-example"><a class="header" href="#cargo-run-example">Cargo Run Example</a></h2>
<pre><code class="language-bash"># Evaluate single response
cargo run --example llm_eval -- \
    --prompt "What is ML?" \
    --response "Machine learning is..."

# Evaluate from file
cargo run --example llm_eval -- \
    --input responses.jsonl \
    --output eval_results.json

# With ground truth
cargo run --example llm_eval -- \
    --input responses.jsonl \
    --ground-truth ground_truth.jsonl
</code></pre>
<h2 id="custom-evaluators"><a class="header" href="#custom-evaluators">Custom Evaluators</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::monitor::llm::{LLMEvaluator, EvalResult};

struct CustomEvaluator {
    // Custom state
}

impl LLMEvaluator for CustomEvaluator {
    fn evaluate_response(
        &amp;mut self,
        run_id: &amp;str,
        prompt: &amp;str,
        response: &amp;str,
        ground_truth: Option&lt;&amp;str&gt;,
    ) -&gt; Result&lt;EvalResult&gt; {
        // Custom evaluation logic
        let relevance = custom_relevance(prompt, response);
        let coherence = custom_coherence(response);
        let groundedness = custom_groundedness(response, ground_truth);
        let harmfulness = custom_harmfulness(response);

        Ok(EvalResult::new(relevance, coherence, groundedness, harmfulness))
    }

    // ... implement other methods
}
<span class="boring">}</span></code></pre></pre>
<h2 id="evaluation-report"><a class="header" href="#evaluation-report">Evaluation Report</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Generate evaluation report
let report = evaluator.generate_report("run-123")?;

println!("{}", report);
<span class="boring">}</span></code></pre></pre>
<p>Output:</p>
<pre><code>=== LLM Evaluation Report ===
Run: run-123
Total evaluations: 100

Metrics Summary:
  Relevance:    0.85 ± 0.12
  Coherence:    0.92 ± 0.08
  Groundedness: 0.78 ± 0.15
  Harmfulness:  0.02 ± 0.05

Token Usage:
  Total tokens: 25,000
  Avg per call: 250

Latency:
  Avg: 450ms
  P95: 850ms
  P99: 1200ms
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<ol>
<li><strong>Always include ground truth</strong> - Enables groundedness measurement</li>
<li><strong>Evaluate on diverse prompts</strong> - Avoid overfitting to specific patterns</li>
<li><strong>Track prompt versions</strong> - Enable A/B testing</li>
<li><strong>Log token usage</strong> - Monitor costs</li>
<li><strong>Set quality thresholds</strong> - Fail builds on low scores</li>
</ol>
<h2 id="see-also"><a class="header" href="#see-also">See Also</a></h2>
<ul>
<li><a href="./overview.html">MLOps Overview</a></li>
<li><a href="./experiment-tracking.html">Experiment Tracking</a></li>
<li><a href="../monitor/quality-gates.html">Quality Gates (Jidoka)</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../mlops/cloud-storage.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../io/overview.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../mlops/cloud-storage.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../io/overview.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../editor.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
